{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import random\n",
    "import re\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"train.csv\")\n",
    "test = pd.read_csv(\"test.csv\")\n",
    "test_labels = pd.read_csv(\"test_labels.csv\")\n",
    "sample_submission = pd.read_csv(\"sample_submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = train[\"comment_text\"][:125000]\n",
    "test_x = train[\"comment_text\"][125000:]\n",
    "\n",
    "train_y_toxic = train[\"toxic\"][:125000]\n",
    "test_y_toxic = train[\"toxic\"][125000:]\n",
    "\n",
    "train_y_severe_toxic = train[\"severe_toxic\"][:125000]\n",
    "test_y_severe_toxic = train[\"severe_toxic\"][125000:]\n",
    "\n",
    "train_y_identity_hate = train[\"identity_hate\"][:125000]\n",
    "test_y_identity_hate = train[\"identity_hate\"][125000:]\n",
    "\n",
    "train_y_insult = train[\"insult\"][:125000]\n",
    "test_y_insult = train[\"insult\"][125000:]\n",
    "\n",
    "train_y_obscene = train[\"obscene\"][:125000]\n",
    "test_y_obscene = train[\"obscene\"][125000:]\n",
    "\n",
    "train_y_threat = train[\"threat\"][:125000]\n",
    "test_y_threat = train[\"threat\"][125000:]\n",
    "\n",
    "train_y_insult = train[\"identity_hate\"][:125000]\n",
    "test_y_insult = train[\"identity_hate\"][125000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# English stopwords incuding punctuations\n",
    "stopword = ['haven', 'be', 'do', 'between', 'same', 'won', 'mustn', 'were', 'by', 'theirs', 'with', \"hasn't\", \n",
    "            'my', 'll', 'him', 'out', 'but', 'd', \"should've\", \"haven't\", 'shouldn', 'all', 'than', 'on', 'aren',\n",
    "            'being', 're', \"weren't\", 'where', 'we', 'his', 'it', \"that'll\", 'while', \"shouldn't\", 'some', 'over', \n",
    "            'yourself', \"needn't\", 'this', 'there', \"mustn't\", 'mightn', 'against', 'hers', 'isn', 'each', 'as', \"won't\",\n",
    "            'should', 'above', 'don', 'themselves', 'itself', 'own', 'to', 'few', \"don't\", 'did', 't', 'wasn', \"isn't\",\n",
    "            \"you'll\", 'up', 'just', 'myself', 'these', 'why', 'those', 'doing', 'shan', 'am', 'under', 'has', 'ourselves',\n",
    "            \"you've\", 'other', 'that', 'i', 'too', 'the', 'which', 'is', 'herself', 'then', 'didn', \"didn't\", 'no', 'more',\n",
    "            'of', 'doesn', 'have', 'her', 'down', 'o', 'not', 'can', 'yourselves', 'any', \"it's\", 'about', 'ours', \"hadn't\",\n",
    "            'he', 'a', 'again', \"she's\", 've', \"wouldn't\", 'only', 'y', 'such', \"couldn't\", 'and', 's', 'himself', 'after', \n",
    "            'they', 'had', 'when', \"you're\", \"doesn't\", 'their', 'will', 'couldn', 'in', 'does', 'or', 'very', \"aren't\", \n",
    "            'what', 'now', 'an', 'until', 'if', 'during', 'she', 'further', \"shan't\", 'your', 'them', 'me', 'because', \n",
    "            'its', 'nor', 'weren', 'yours', 'into', 'wouldn', 'through', 'are', 'having', \"mightn't\", 'whom', 'here', \n",
    "            'off', 'been', 'both', 'at', 'below', 'for', 'needn', 'was', 'once', 'ain', 'our', 'before', 'how', 'ma', \n",
    "            'hadn', \"you'd\", 'most', 'who', 'you', 'so', \"wasn't\", 'hasn', 'm', 'from' ,'(' ,')' ,'[' ,']','{' ,'}','\"' ,'#',\n",
    "            '@' ,'!','$' ,'%','^' ,'&','*' ,'+','-' ,'_',';',':',\"<\",\">\",'.',\"/\",\"?\",\"~\" ,\"=\",\"~\" ,\"`\",\"|\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CountVectorizer - text_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text  import CountVectorizer\n",
    "\n",
    "vect = CountVectorizer(stop_words=stopword, lowercase=True, analyzer='word' ,ngram_range=(1,2),\n",
    "                       min_df=0.1, max_df=0.7, max_features=100)\n",
    "\n",
    "train_x_count = vect.fit_transform(train_x)\n",
    "test_x_count = vect.transform(test_x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### >>Toxic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the random forest...\n",
      "Accuracy for toxic comment :  0.9039078996847069\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      1.00      0.95     31274\n",
      "          1       0.26      0.00      0.01      3297\n",
      "\n",
      "avg / total       0.84      0.90      0.86     34571\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print (\"Training the random forest...\")\n",
    "\n",
    "forest = RandomForestClassifier(n_estimators = 20)\n",
    "forest = forest.fit( train_x_count, train_y_toxic )\n",
    "result = forest.predict(test_x_count)\n",
    "\n",
    "accuracy = accuracy_score(result , test_y_toxic)\n",
    "print(\"Accuracy for toxic comment : \",accuracy)\n",
    "\n",
    "print(classification_report(test_y_toxic,result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the Naive_bayes\n",
      "Accuracy for toxic comment :  0.8992218911804691\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      0.99      0.95     31274\n",
      "          1       0.14      0.01      0.02      3297\n",
      "\n",
      "avg / total       0.83      0.90      0.86     34571\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Training the Naive_bayes\")\n",
    "\n",
    "nb = MultinomialNB()\n",
    "nb = nb.fit(train_x_count, train_y_toxic)\n",
    "result = nb.predict(test_x_count)\n",
    "\n",
    "accuracy = accuracy_score(result , test_y_toxic)\n",
    "print(\"Accuracy for toxic comment : \",accuracy)\n",
    "\n",
    "print(classification_report(test_y_toxic,result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### >> Severe Toxic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the random forest...\n",
      "Accuracy for toxic comment :  0.9901940933152064\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      1.00      1.00     34234\n",
      "          1       0.00      0.00      0.00       337\n",
      "\n",
      "avg / total       0.98      0.99      0.99     34571\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print (\"Training the random forest...\")\n",
    "\n",
    "forest = RandomForestClassifier(n_estimators = 20)\n",
    "forest = forest.fit( train_x_count, train_y_severe_toxic )\n",
    "result = forest.predict(test_x_count)\n",
    "\n",
    "accuracy = accuracy_score(result , test_y_severe_toxic)\n",
    "print(\"Accuracy for toxic comment : \",accuracy)\n",
    "\n",
    "print(classification_report(test_y_severe_toxic,result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the Naive_bayes\n",
      "Accuracy for toxic comment :  0.9877064591709814\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      1.00      0.99     34234\n",
      "          1       0.01      0.00      0.00       337\n",
      "\n",
      "avg / total       0.98      0.99      0.98     34571\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Training the Naive_bayes\")\n",
    "\n",
    "nb = MultinomialNB()\n",
    "nb = nb.fit(train_x_count, train_y_severe_toxic)\n",
    "result = nb.predict(test_x_count)\n",
    "\n",
    "accuracy = accuracy_score(result , test_y_severe_toxic)\n",
    "print(\"Accuracy for toxic comment : \",accuracy)\n",
    "\n",
    "print(classification_report(test_y_severe_toxic,result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### >> Insult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the random forest...\n",
      "Accuracy for toxic comment :  0.9904833530994186\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      1.00      1.00     34246\n",
      "          1       0.00      0.00      0.00       325\n",
      "\n",
      "avg / total       0.98      0.99      0.99     34571\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print (\"Training the random forest...\")\n",
    "\n",
    "forest = RandomForestClassifier(n_estimators = 20)\n",
    "forest = forest.fit( train_x_count, train_y_insult )\n",
    "result = forest.predict(test_x_count)\n",
    "\n",
    "accuracy = accuracy_score(result , test_y_insult)\n",
    "print(\"Accuracy for toxic comment : \",accuracy)\n",
    "\n",
    "print(classification_report(test_y_insult,result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the Naive_bayes\n",
      "Accuracy for toxic comment :  0.9891527580920425\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      1.00      0.99     34246\n",
      "          1       0.00      0.00      0.00       325\n",
      "\n",
      "avg / total       0.98      0.99      0.99     34571\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Training the Naive_bayes\")\n",
    "\n",
    "nb = MultinomialNB()\n",
    "nb = nb.fit(train_x_count, train_y_insult)\n",
    "result = nb.predict(test_x_count)\n",
    "\n",
    "accuracy = accuracy_score(result , test_y_insult)\n",
    "print(\"Accuracy for toxic comment : \",accuracy)\n",
    "\n",
    "print(classification_report(test_y_insult,result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### >> Obscene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the random forest...\n",
      "Accuracy for toxic comment :  0.947296867316537\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      1.00      0.97     32765\n",
      "          1       0.17      0.00      0.00      1806\n",
      "\n",
      "avg / total       0.91      0.95      0.92     34571\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print (\"Training the random forest...\")\n",
    "\n",
    "forest = RandomForestClassifier(n_estimators = 20)\n",
    "forest = forest.fit( train_x_count, train_y_obscene )\n",
    "result = forest.predict(test_x_count)\n",
    "\n",
    "accuracy = accuracy_score(result , test_y_obscene)\n",
    "print(\"Accuracy for toxic comment : \",accuracy)\n",
    "\n",
    "print(classification_report(test_y_obscene,result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the Naive_bayes\n",
      "Accuracy for toxic comment :  0.9445199733880999\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      1.00      0.97     32765\n",
      "          1       0.07      0.00      0.01      1806\n",
      "\n",
      "avg / total       0.90      0.94      0.92     34571\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Training the Naive_bayes\")\n",
    "\n",
    "nb = MultinomialNB()\n",
    "nb = nb.fit(train_x_count, train_y_obscene)\n",
    "result = nb.predict(test_x_count)\n",
    "\n",
    "accuracy = accuracy_score(result , test_y_obscene)\n",
    "print(\"Accuracy for toxic comment : \",accuracy)\n",
    "\n",
    "print(classification_report(test_y_obscene,result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### >> Threat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the random forest...\n",
      "Accuracy for toxic comment :  0.997107402157878\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00     34473\n",
      "          1       0.00      0.00      0.00        98\n",
      "\n",
      "avg / total       0.99      1.00      1.00     34571\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print (\"Training the random forest...\")\n",
    "\n",
    "forest = RandomForestClassifier(n_estimators = 20)\n",
    "forest = forest.fit( train_x_count, train_y_threat )\n",
    "result = forest.predict(test_x_count)\n",
    "\n",
    "accuracy = accuracy_score(result , test_y_threat)\n",
    "print(\"Accuracy for toxic comment : \",accuracy)\n",
    "\n",
    "print(classification_report(test_y_threat,result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the Naive_bayes\n",
      "Accuracy for toxic comment :  0.9959792889994504\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00     34473\n",
      "          1       0.00      0.00      0.00        98\n",
      "\n",
      "avg / total       0.99      1.00      1.00     34571\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Training the Naive_bayes\")\n",
    "\n",
    "nb = MultinomialNB()\n",
    "nb = nb.fit(train_x_count, train_y_threat)\n",
    "result = nb.predict(test_x_count)\n",
    "\n",
    "accuracy = accuracy_score(result , test_y_threat)\n",
    "print(\"Accuracy for toxic comment : \",accuracy)\n",
    "\n",
    "print(classification_report(test_y_threat,result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### >> Identity_hate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the random forest...\n",
      "Accuracy for toxic comment :  0.9905122790778398\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      1.00      1.00     34246\n",
      "          1       0.00      0.00      0.00       325\n",
      "\n",
      "avg / total       0.98      0.99      0.99     34571\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print (\"Training the random forest...\")\n",
    "\n",
    "forest = RandomForestClassifier(n_estimators = 20)\n",
    "forest = forest.fit( train_x_count, train_y_identity_hate )\n",
    "result = forest.predict(test_x_count)\n",
    "\n",
    "accuracy = accuracy_score(result , test_y_identity_hate)\n",
    "print(\"Accuracy for toxic comment : \",accuracy)\n",
    "\n",
    "print(classification_report(test_y_identity_hate,result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the Naive_bayes\n",
      "Accuracy for toxic comment :  0.9891527580920425\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      1.00      0.99     34246\n",
      "          1       0.00      0.00      0.00       325\n",
      "\n",
      "avg / total       0.98      0.99      0.99     34571\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Training the Naive_bayes\")\n",
    "\n",
    "nb = MultinomialNB()\n",
    "nb = nb.fit(train_x_count, train_y_identity_hate)\n",
    "result = nb.predict(test_x_count)\n",
    "\n",
    "accuracy = accuracy_score(result , test_y_identity_hate)\n",
    "print(\"Accuracy for toxic comment : \",accuracy)\n",
    "\n",
    "print(classification_report(test_y_identity_hate,result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TfidfVectorize - text_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf = TfidfVectorizer(stop_words=stopword, lowercase=True, analyzer='word',\n",
    "                       ngram_range=(1,2), min_df=0.1, max_df=0.7, max_features=100)\n",
    "\n",
    "train_x_tfidf = tfidf.fit_transform(train_x) \n",
    "\n",
    "test_x_tfidf = tfidf.transform(test_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### >> toxic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the random forest...\n",
      "Accuracy for toxic comment :  0.9039657516415492\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      1.00      0.95     31274\n",
      "          1       0.27      0.00      0.01      3297\n",
      "\n",
      "avg / total       0.84      0.90      0.86     34571\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print (\"Training the random forest...\")\n",
    "\n",
    "forest = RandomForestClassifier(n_estimators = 20)\n",
    "forest = forest.fit( train_x_tfidf, train_y_toxic )\n",
    "result = forest.predict(test_x_tfidf)\n",
    "\n",
    "accuracy = accuracy_score(result , test_y_toxic)\n",
    "print(\"Accuracy for toxic comment : \",accuracy)\n",
    "\n",
    "print(classification_report(test_y_toxic,result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the Naive_bayes\n",
      "Accuracy for toxic comment :  0.9046310491452373\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      1.00      0.95     31274\n",
      "          1       0.00      0.00      0.00      3297\n",
      "\n",
      "avg / total       0.82      0.90      0.86     34571\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\khush\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print(\"Training the Naive_bayes\")\n",
    "\n",
    "nb = MultinomialNB()\n",
    "nb = nb.fit(train_x_tfidf, train_y_toxic)\n",
    "result = nb.predict(test_x_tfidf)\n",
    "\n",
    "accuracy = accuracy_score(result , test_y_toxic)\n",
    "print(\"Accuracy for toxic comment : \",accuracy)\n",
    "\n",
    "print(classification_report(test_y_toxic,result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### >> severe_toxic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the random forest...\n",
      "Accuracy for toxic comment :  0.9901651673367852\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      1.00      1.00     34234\n",
      "          1       0.00      0.00      0.00       337\n",
      "\n",
      "avg / total       0.98      0.99      0.99     34571\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print (\"Training the random forest...\")\n",
    "\n",
    "forest = RandomForestClassifier(n_estimators = 20)\n",
    "forest = forest.fit( train_x_tfidf, train_y_severe_toxic )\n",
    "result = forest.predict(test_x_tfidf)\n",
    "\n",
    "accuracy = accuracy_score(result , test_y_severe_toxic)\n",
    "print(\"Accuracy for toxic comment : \",accuracy)\n",
    "\n",
    "print(classification_report(test_y_severe_toxic,result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the Naive_bayes\n",
      "Accuracy for toxic comment :  0.9902519452720489\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      1.00      1.00     34234\n",
      "          1       0.00      0.00      0.00       337\n",
      "\n",
      "avg / total       0.98      0.99      0.99     34571\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\khush\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print(\"Training the Naive_bayes\")\n",
    "\n",
    "nb = MultinomialNB()\n",
    "nb = nb.fit(train_x_tfidf, train_y_severe_toxic)\n",
    "result = nb.predict(test_x_tfidf)\n",
    "\n",
    "accuracy = accuracy_score(result , test_y_severe_toxic)\n",
    "print(\"Accuracy for toxic comment : \",accuracy)\n",
    "\n",
    "print(classification_report(test_y_severe_toxic,result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### >> insult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the random forest...\n",
      "Accuracy for toxic comment :  0.9905122790778398\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      1.00      1.00     34246\n",
      "          1       0.00      0.00      0.00       325\n",
      "\n",
      "avg / total       0.98      0.99      0.99     34571\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print (\"Training the random forest...\")\n",
    "\n",
    "forest = RandomForestClassifier(n_estimators = 20)\n",
    "forest = forest.fit( train_x_tfidf, train_y_insult )\n",
    "result = forest.predict(test_x_tfidf)\n",
    "\n",
    "accuracy = accuracy_score(result , test_y_insult)\n",
    "print(\"Accuracy for toxic comment : \",accuracy)\n",
    "\n",
    "print(classification_report(test_y_insult,result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the Naive_bayes\n",
      "Accuracy for toxic comment :  0.9905990570131035\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      1.00      1.00     34246\n",
      "          1       0.00      0.00      0.00       325\n",
      "\n",
      "avg / total       0.98      0.99      0.99     34571\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\khush\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print(\"Training the Naive_bayes\")\n",
    "\n",
    "nb = MultinomialNB()\n",
    "nb = nb.fit(train_x_tfidf, train_y_insult)\n",
    "result = nb.predict(test_x_tfidf)\n",
    "\n",
    "accuracy = accuracy_score(result , test_y_insult)\n",
    "print(\"Accuracy for toxic comment : \",accuracy)\n",
    "\n",
    "print(classification_report(test_y_insult,result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### >> obscene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the random forest...\n",
      "Accuracy for toxic comment :  0.9470943854675884\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      1.00      0.97     32765\n",
      "          1       0.13      0.00      0.00      1806\n",
      "\n",
      "avg / total       0.91      0.95      0.92     34571\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print (\"Training the random forest...\")\n",
    "\n",
    "forest = RandomForestClassifier(n_estimators = 20)\n",
    "forest = forest.fit( train_x_tfidf, train_y_obscene )\n",
    "result = forest.predict(test_x_tfidf)\n",
    "\n",
    "accuracy = accuracy_score(result , test_y_obscene)\n",
    "print(\"Accuracy for toxic comment : \",accuracy)\n",
    "\n",
    "print(classification_report(test_y_obscene,result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the Naive_bayes\n",
      "Accuracy for toxic comment :  0.9477596829712766\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      1.00      0.97     32765\n",
      "          1       0.00      0.00      0.00      1806\n",
      "\n",
      "avg / total       0.90      0.95      0.92     34571\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\khush\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print(\"Training the Naive_bayes\")\n",
    "\n",
    "nb = MultinomialNB()\n",
    "nb = nb.fit(train_x_tfidf, train_y_obscene)\n",
    "result = nb.predict(test_x_tfidf)\n",
    "\n",
    "accuracy = accuracy_score(result , test_y_obscene)\n",
    "print(\"Accuracy for toxic comment : \",accuracy)\n",
    "\n",
    "print(classification_report(test_y_obscene,result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### >> threat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the random forest...\n",
      "Accuracy for toxic comment :  0.9971652541147205\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00     34473\n",
      "          1       0.00      0.00      0.00        98\n",
      "\n",
      "avg / total       0.99      1.00      1.00     34571\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\khush\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print (\"Training the random forest...\")\n",
    "\n",
    "forest = RandomForestClassifier(n_estimators = 20)\n",
    "forest = forest.fit( train_x_tfidf, train_y_threat )\n",
    "result = forest.predict(test_x_tfidf)\n",
    "\n",
    "accuracy = accuracy_score(result , test_y_threat)\n",
    "print(\"Accuracy for toxic comment : \",accuracy)\n",
    "\n",
    "print(classification_report(test_y_threat,result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the Naive_bayes\n",
      "Accuracy for toxic comment :  0.9971652541147205\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00     34473\n",
      "          1       0.00      0.00      0.00        98\n",
      "\n",
      "avg / total       0.99      1.00      1.00     34571\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\khush\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print(\"Training the Naive_bayes\")\n",
    "\n",
    "nb = MultinomialNB()\n",
    "nb = nb.fit(train_x_tfidf, train_y_threat)\n",
    "result = nb.predict(test_x_tfidf)\n",
    "\n",
    "accuracy = accuracy_score(result , test_y_threat)\n",
    "print(\"Accuracy for toxic comment : \",accuracy)\n",
    "\n",
    "print(classification_report(test_y_threat,result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### >> identity_hate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the random forest...\n",
      "Accuracy for toxic comment :  0.9905701310346823\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      1.00      1.00     34246\n",
      "          1       0.00      0.00      0.00       325\n",
      "\n",
      "avg / total       0.98      0.99      0.99     34571\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print (\"Training the random forest...\")\n",
    "\n",
    "forest = RandomForestClassifier(n_estimators = 20)\n",
    "forest = forest.fit( train_x_tfidf, train_y_identity_hate )\n",
    "result = forest.predict(test_x_tfidf)\n",
    "\n",
    "accuracy = accuracy_score(result , test_y_identity_hate)\n",
    "print(\"Accuracy for toxic comment : \",accuracy)\n",
    "\n",
    "print(classification_report(test_y_identity_hate,result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the Naive_bayes\n",
      "Accuracy for toxic comment :  0.9905990570131035\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      1.00      1.00     34246\n",
      "          1       0.00      0.00      0.00       325\n",
      "\n",
      "avg / total       0.98      0.99      0.99     34571\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\khush\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print(\"Training the Naive_bayes\")\n",
    "\n",
    "nb = MultinomialNB()\n",
    "nb = nb.fit(train_x_tfidf, train_y_identity_hate)\n",
    "result = nb.predict(test_x_tfidf)\n",
    "\n",
    "accuracy = accuracy_score(result , test_y_identity_hate)\n",
    "print(\"Accuracy for toxic comment : \",accuracy)\n",
    "\n",
    "print(classification_report(test_y_identity_hate,result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
